# Pipeline de AnalÃ­ticas del Club

Una soluciÃ³n integral de analÃ­ticas construida sobre principios de stack de datos moderno, que incluye esquema estrella, transformaciones dbt, orquestaciÃ³n Airflow e ingesta de datos con Python. Este fue un proyecto entregado como resultado de un Trabajo Final Integrador (que eventualmente mejorÃ© un poco) para la asignatura de IngenierÃ­a de Datos I.

## ğŸ—ï¸ Resumen de Arquitectura

```mermaid
graph TB
    subgraph "Fuentes de Datos"
        A[Archivos CSV] --> B[Ingesta Python]
        C[Base de Datos OLTP] --> D[Esquema Raw]
    end
    
    subgraph "Procesamiento de Datos"
        B --> E[Almacenamiento de Datos Raw]
        D --> E
        E --> F[dbt Staging]
        F --> G[dbt Marts]
        G --> H[Esquema Estrella]
    end
    
    subgraph "OrquestaciÃ³n"
        I[DAG Airflow] --> B
        I --> F
        I --> J[Pruebas dbt]
        I --> K[Verificaciones Soda]
        I --> L[ExportaciÃ³n de MÃ©tricas]
    end
    
    subgraph "AnalÃ­ticas y VisualizaciÃ³n"
        H --> M[Dashboard Streamlit]
        L --> N[MÃ©tricas Diarias]
    end
    
    subgraph "Calidad y Pruebas"
        J --> O[Calidad de Datos]
        K --> O
        P[pytest] --> Q[Pruebas Unitarias]
        R[GitHub Actions] --> S[Pipeline CI/CD]
    end
```

## ğŸ“Š Modelo de Datos

### DiseÃ±o de Esquema Estrella

**Hechos:**
- `fact_ticket_sales` - Transacciones de venta de entradas
- `fact_dues_payments` - Pagos de cuotas de membresÃ­a
- `fact_attendance` - Registros de asistencia a eventos

**Dimensiones:**
- `dim_member` - InformaciÃ³n de miembros con claves suplentes
- `dim_event` - Eventos, partidos y actividades
- `dim_date` - DimensiÃ³n de fecha comprensiva (2020-2030)

### MÃ©tricas Clave

- **MRR (Ingresos Recurrentes Mensuales)** - De pagos de cuotas
- **ARPPM (Ingresos Promedio por Miembro Pagador)** - Eficiencia de ingresos
- **Ingresos por Eventos** - Rendimiento de venta de entradas
- **Tasa de RetenciÃ³n** - MÃ©tricas de compromiso de miembros

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- Docker & Docker Compose
- Python 3.9+
- PostgreSQL 15+

### ConfiguraciÃ³n en 5 Comandos

```bash
# 1. Clonar y navegar
git clone <repository-url>
cd club-analytics

# 2. Iniciar servicios
docker-compose up -d

# 3. Esperar a que los servicios se inicialicen
sleep 30

# 4. Ejecutar pipeline de datos
docker-compose exec airflow-webserver python /opt/airflow/scripts/data_ingestion.py

# 5. Ver dashboard
streamlit run streamlit_app.py
```

## ğŸ“ Estructura del Proyecto

```
club-analytics/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ club_analytics_pipeline.py
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ packages.yml
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ init/
â”‚   â”œâ”€â”€ star_schema.sql
â”‚   â””â”€â”€ populate_star_schema.sql
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ data_ingestion.py
â”œâ”€â”€ soda/
â”‚   â””â”€â”€ configuration.yml
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_ingestion.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ streamlit_app.py
```

## ğŸ”„ Flujo del Pipeline de Datos

### 1. Ingesta de Datos
- **Script Python**: Simula generaciÃ³n diaria de CSV
- **Fuentes**: Datos de entradas, cuotas, asistencia
- **Formato**: Archivos CSV en `/data/raw/`

### 2. TransformaciÃ³n de Datos (dbt)
- **Staging**: Limpieza y estandarizaciÃ³n de datos raw
- **Marts**: LÃ³gica de negocio y poblaciÃ³n del esquema estrella
- **Pruebas**: ValidaciÃ³n de calidad de datos

### 3. OrquestaciÃ³n (Airflow)
- **DAG**: EjecuciÃ³n diaria del pipeline
- **Tareas**: Ingesta â†’ dbt â†’ Calidad â†’ MÃ©tricas
- **Monitoreo**: Interfaz web en `http://localhost:8080`

### 4. Calidad de Datos
- **Pruebas dbt**: Ãšnicos, no nulos, integridad referencial
- **Verificaciones Soda**: Reglas de negocio y validaciÃ³n de datos
- **Monitoreo**: Puertas de calidad automatizadas

## ğŸ§ª Estrategia de Pruebas

### Pruebas Unitarias (pytest)
```bash
pytest tests/ -v
```

### Pruebas dbt
```bash
cd dbt
dbt test
```

### Calidad de Datos Soda
```bash
soda scan -d postgres_local -c soda/configuration.yml
```

### Pipeline CI/CD
- **GitHub Actions**: Pruebas automatizadas en push/PR
- **Docker Build**: ValidaciÃ³n de servicios
- **Escaneo de Seguridad**: Verificaciones de vulnerabilidades

## ğŸ“ˆ CaracterÃ­sticas Clave

### Capacidades de AnalÃ­ticas
- **Esquema Estrella**: Optimizado para consultas analÃ­ticas
- **Claves Suplentes**: Referencias consistentes de dimensiones
- **DimensiÃ³n de Fecha**: AnÃ¡lisis temporal comprensivo
- **MÃ©tricas de Negocio**: MRR, ARPPM, retenciÃ³n

### Calidad de Datos
- **Integridad Referencial**: ValidaciÃ³n de claves forÃ¡neas
- **Reglas de Negocio**: LÃ³gica de validaciÃ³n personalizada
- **Frescura de Datos**: Monitoreo automatizado
- **DetecciÃ³n de AnomalÃ­as**: ValidaciÃ³n estadÃ­stica

### VisualizaciÃ³n
- **Dashboard Streamlit**: AnalÃ­ticas interactivas
- **MÃ©tricas en Tiempo Real**: Actualizaciones de datos en vivo
- **Filtrado**: Rangos de fechas, tipos de eventos, estado de miembros
- **ExportaciÃ³n**: ExportaciÃ³n de datos CSV/JSON

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno
```bash
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DATABASE=club_analytics
```

### ConfiguraciÃ³n dbt
```yaml
# profiles.yml
club_analytics:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: postgres
      password: postgres
      port: 5432
      dbname: club_analytics
      schema: analytics
```

### ConfiguraciÃ³n Airflow
- **Ejecutor**: LocalExecutor
- **Base de Datos**: PostgreSQL
- **DAGs**: `/opt/airflow/dags`
- **Logs**: `/opt/airflow/logs`

## ğŸ“Š Consultas de Ejemplo

### AnÃ¡lisis de Ingresos
```sql
-- Tendencia MRR mensual
SELECT 
    dd.year,
    dd.month_name,
    SUM(fdp.payment_amount) as mrr
FROM analytics.fact_dues_payments fdp
JOIN analytics.dim_date dd ON fdp.date_key = dd.date_key
WHERE fdp.is_paid = true
GROUP BY dd.year, dd.month_name
ORDER BY dd.year, dd.month;
```

### Compromiso de Miembros
```sql
-- Top eventos por asistencia
SELECT 
    de.event_name,
    de.event_type,
    COUNT(fa.attendance_key) as attendance_count
FROM analytics.fact_attendance fa
JOIN analytics.dim_event de ON fa.event_key = de.event_key
GROUP BY de.event_name, de.event_type
ORDER BY attendance_count DESC;
```

### AnÃ¡lisis de RetenciÃ³n
```sql
-- RetenciÃ³n de miembros por mes de registro
SELECT 
    dm.registration_year,
    dm.registration_month,
    COUNT(*) as total_members,
    COUNT(CASE WHEN dm.status_active THEN 1 END) as active_members,
    ROUND(COUNT(CASE WHEN dm.status_active THEN 1 END)::float / COUNT(*) * 100, 2) as retention_rate
FROM analytics.dim_member dm
GROUP BY dm.registration_year, dm.registration_month
ORDER BY dm.registration_year, dm.registration_month;
```

## ğŸš€ Despliegue en la Nube (Opcional)

### ConfiguraciÃ³n AWS Free Tier
```bash
# S3 para almacenamiento de datos raw
aws s3 mb s3://club-analytics-raw

# Redshift Serverless para data warehouse
aws redshift-serverless create-workgroup --workgroup-name club-analytics

# Glue para procesamiento ETL
aws glue create-job --name club-analytics-etl
```

### Databricks Community
```bash
# Delta Lake para almacenamiento de datos
spark.sql("CREATE DATABASE IF NOT EXISTS club_analytics")

# Tablas Delta para hechos y dimensiones
spark.sql("CREATE TABLE fact_ticket_sales USING DELTA")
```

## ğŸ“š DocumentaciÃ³n

### Linaje de Datos
- **Documentos dbt**: `dbt docs generate && dbt docs serve`
- **GrÃ¡fico de Linaje**: RepresentaciÃ³n visual del flujo de datos
- **Dependencias de Modelos**: Cadena de transformaciÃ³n clara

### DocumentaciÃ³n de API
- **Streamlit**: DocumentaciÃ³n de dashboard interactivo
- **Airflow**: DocumentaciÃ³n de DAG y tareas
- **dbt**: DocumentaciÃ³n de modelos y pruebas

## ğŸ¤ Contribuir ;D

1. Fork del repositorio
2. Crear una rama de feature
3. Hacer cambios con pruebas
4. Ejecutar pipeline CI/CD
5. Enviar un pull request

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo LICENSE para detalles.

## ğŸ†˜ Soporte

- **Issues**: GitHub Issues para reportes de bugs
- **Discussions**: GitHub Discussions para preguntas
- **DocumentaciÃ³n**: README y comentarios en lÃ­nea de cÃ³digo

---

**Construido con â¤ï¸ por Ivo Danko, usando principios de stack de datos moderno**


